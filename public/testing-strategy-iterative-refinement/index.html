<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=58150&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Strategy testing: avoid the waterfall strategy trap with iterative refinement. | Drafting Strategy</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="If I could only popularize one idea about technical strategy, it would be that prematurely applying pressure to a strategy&rsquo;s rollout prevents evaluating whether the strategy is effective. Pressure changes behavior in profound ways, and many of those changes are intended to make you believe your strategy is working while minimizing change to the status quo (if you&rsquo;re an executive) or get your strategy repealed (if you&rsquo;re not an executive). Neither is particular helpful.">
    <meta name="generator" content="Hugo 0.128.2">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    <meta name="author" content="map[name:Will Larson]">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/static/pygments.css">
  


    

    
      

    

    

    
      <link rel="canonical" href="http://localhost:58150/testing-strategy-iterative-refinement/">
    

    <meta property="og:url" content="http://localhost:58150/testing-strategy-iterative-refinement/">
  <meta property="og:site_name" content="Drafting Strategy">
  <meta property="og:title" content="Strategy testing: avoid the waterfall strategy trap with iterative refinement.">
  <meta property="og:description" content="If I could only popularize one idea about technical strategy, it would be that prematurely applying pressure to a strategy’s rollout prevents evaluating whether the strategy is effective. Pressure changes behavior in profound ways, and many of those changes are intended to make you believe your strategy is working while minimizing change to the status quo (if you’re an executive) or get your strategy repealed (if you’re not an executive). Neither is particular helpful.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="refinement">
    <meta property="article:published_time" content="2024-09-25T17:00:00-07:00">
    <meta property="article:modified_time" content="2024-09-25T17:00:00-07:00">
    <meta property="article:tag" content="Strategy">
    <meta property="article:tag" content="Eng-Strategy-Book">
    <meta property="og:image" content="http://localhost:58150/static/author.png">

  <meta itemprop="name" content="Strategy testing: avoid the waterfall strategy trap with iterative refinement.">
  <meta itemprop="description" content="If I could only popularize one idea about technical strategy, it would be that prematurely applying pressure to a strategy’s rollout prevents evaluating whether the strategy is effective. Pressure changes behavior in profound ways, and many of those changes are intended to make you believe your strategy is working while minimizing change to the status quo (if you’re an executive) or get your strategy repealed (if you’re not an executive). Neither is particular helpful.">
  <meta itemprop="datePublished" content="2024-09-25T17:00:00-07:00">
  <meta itemprop="dateModified" content="2024-09-25T17:00:00-07:00">
  <meta itemprop="wordCount" content="2162">
  <meta itemprop="image" content="http://localhost:58150/static/author.png">
  <meta itemprop="keywords" content="Strategy,Eng-Strategy-Book">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:58150/static/author.png">
  <meta name="twitter:title" content="Strategy testing: avoid the waterfall strategy trap with iterative refinement.">
  <meta name="twitter:description" content="If I could only popularize one idea about technical strategy, it would be that prematurely applying pressure to a strategy’s rollout prevents evaluating whether the strategy is effective. Pressure changes behavior in profound ways, and many of those changes are intended to make you believe your strategy is working while minimizing change to the status quo (if you’re an executive) or get your strategy repealed (if you’re not an executive). Neither is particular helpful.">

	

  </head><body class="ma0 avenir bg-white development">

    
   
  <header>
  <div class="bg-white">
    <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 no-underline black-90 dib">
      
        Drafting Strategy
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="no-underline black-90" href="/about" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="no-underline black-90" href="" title=" page">
              
            </a>
          </li>
          
        </ul>
      
      















    </div>
  </div>
  
    
</nav>

  </div>
</header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      
      
      <h1 class="f1 athelas mt3 mb3">Strategy testing: avoid the waterfall strategy trap with iterative refinement.</h1>
      
      

      
      

    </header>
    <div class="nested-copy-line-height lh-copy serif f5 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>If I could only popularize one idea about technical strategy, it would be that
prematurely applying pressure to a strategy&rsquo;s rollout prevents evaluating whether the strategy is effective.
Pressure changes behavior in profound ways, and many of those changes are intended to make you believe your
strategy is working while minimizing change to the status quo (if you&rsquo;re an executive)
or get your strategy repealed (if you&rsquo;re not an executive). Neither is particular helpful.</p>
<p>While some strategies are obviously wrong from the beginning, it&rsquo;s much more common to see reasonable strategies that
fail because they didn&rsquo;t get the small details right.
Premature pressure is one common cause of a more general phenomenon:
most strategies are developed in a waterfall model,
finalizing their approach before incorporating the lessons that realities teaches
when you attempt the strategy in practice.</p>
<p>One effective mechanism to avoid the waterfall strategy trap is explicitly testing your strategy to refine the details.
This chapter describes the mechanics of strategy testing:</p>
<ul>
<li>when it&rsquo;s important to test strategy (and when it isn&rsquo;t)</li>
<li>how to test strategy</li>
<li>when you should stop testing</li>
<li>roles in strategy testing: sponsor vs guide</li>
<li>metrics and meetings to run a strategy testing</li>
<li>how to identify a strategy that skipped testing</li>
<li>what to do when a strategy has progressed too far without testing</li>
</ul>
<p>Let&rsquo;s get into the details.</p>
<hr>
<p><em>This is an exploratory, draft chapter for a book on engineering strategy that I&rsquo;m brainstorming in <a href="/tags/eng-strategy-book/">#eng-strategy-book</a>.</em>
<em>As such, some of the links go to other draft chapters, both published drafts and very early, unpublished drafts.</em></p>
<p><em>Many of the ideas here came together while working with <a href="https://www.linkedin.com/in/shawnamartell/">Shawna Martell</a>, <a href="https://www.linkedin.com/in/danfike/">Dan Fike</a>, <a href="https://www.linkedin.com/in/madhurisarma/">Madhuri Sarma</a>, and many others in Carta Engineering.</em></p>
<h2 id="when-to-test-strategy">When to test strategy</h2>
<p>Strategy testing is ensuring that a strategy will accomplish its intended goal at a cost that you&rsquo;re willing to pay.
This means it needs to happen prior to implementing a strategy, usually in a strategy&rsquo;s early development stages.</p>
<p>Afew examples of when to test common strategy topics:</p>
<ul>
<li>Integrating a recent acquisition might focus on getting a single API integration working
before finalizing how the overall approach goes.</li>
<li>A developer productivity strategy focused on requiring typing in a Python codebase might
start by having an experienced team member type an important module.</li>
<li>A service migration might attempt migrating both a simple component (to test migration tooling)
and a highly complex component (to test integration complexity) before moving to a broader rollout.</li>
</ul>
<p>In every case, the two most important pieces are testing before finalizing the strategy, and testing narrowly with a focus
on the underlying mechanics of the approach rather than getting caught up in solving broad problems like motivating adoption and addressing conflicting incentives.</p>
<p>That&rsquo;s not to say that you need to test every strategy. A few of the common cases where you might not want to test a strategy are:</p>
<ul>
<li>When you&rsquo;re dealing with a <a href="/when-write-down-engineering-strategy/">permissive strategy</a> that&rsquo;s very cheap to apply,
testing is often not too important; indeed, you can consider most highly-permissive strategies as a test
of whether it&rsquo;s effective to implement a similar, but less permissive, strategy in the future.</li>
<li>Where testing isn&rsquo;t viable for some reason. For example, a hiring strategy where you shift hiring into
certain regions isn&rsquo;t something you can test in most cases, it&rsquo;s something you might need to run for several years
to get meaningful signal on results.</li>
<li>There are also cases where you have such high conviction in a given strategy that it&rsquo;s not worth testing, perhaps
because you&rsquo;ve done something nearly identical at the same company before.
Hubris comes before the fall, so I&rsquo;m generally skeptical of this category.</li>
</ul>
<p>That said, my experience is that you should try very hard to find a way to test every strategy.
You certainly should not try hard to convince yourself testing a strategy isn&rsquo;t worthwhile.
Testing is so, so much cheaper than implementing a bad strategy, that it&rsquo;s almost always a good investment of time and energy.</p>
<h2 id="how-to-test-strategy">How to test strategy</h2>
<p>For a valuable step that&rsquo;s so often skipped, strategy testing is relatively straightforward.
The approach I&rsquo;ve found effective is:</p>
<ol>
<li>
<p>Identify the narrowest, deepest available slice of your strategy, and iterate on applying your strategy to that slice until you&rsquo;re confident the approach works well.</p>
<p>For example, if you&rsquo;re testing a new release strategy for your Product Engineering organization,
decide to release exactly one important release following the new approach.</p>
</li>
<li>
<p>As you iterate, identify metrics that help you verify the approach is working; note that these aren&rsquo;t metrics to measure adoption, instead that measure impact of the change.</p>
<p>For example, metrics that show the new release process reduces customer impact, or drives more top-of-funnel visitors.</p>
</li>
<li>
<p>Operate from the belief that people are well-meaning, and strategy failures are due to excess friction and poor ergonomics.</p>
<p>For example, assume the release tooling is too complex if people aren&rsquo;t using it. (Definitely don&rsquo;t assume that people are too resistent to change.)</p>
</li>
<li>
<p>Keep refining until you have conviction that your strategy&rsquo;s details work in practice, or that the strategy needs to be approached from a new direction.</p>
<p>For example, if the metrics you identified before show the new release process has significantly
reduced customer impact of the new release.</p>
</li>
</ol>
<p>The most important details are the things <em>not</em> to do.
Don&rsquo;t go broad where impact <em>feels</em> higher but iteration cycles are slower.
Don&rsquo;t get caught up on <em>forcing</em> adoption such that you&rsquo;re distracted from improving the underlying mechanics.
Finally, don&rsquo;t get so attached to your current approach that you can&rsquo;t accept that it might not be working.
Strategy testing is only valuable because many strategies don&rsquo;t work as intended, and it&rsquo;s much cheaper
to learn that early.</p>
<h2 id="testing-roles-sponsors-and-guides">Testing roles: sponsors and guides</h2>
<p>Sometimes the strategy testing process is lead by one individual who is able to sponsor the work
(a principal engineer at a smaller company, an executive, etc) and also coordinate the day-to-day work of validating
the approach (a principal engineer at a larger company, an engineering manager, a technical program manager, etc).
It&rsquo;s even more common for these responsibilities to split between two roles: <strong>sponsor</strong> and a <strong>guide</strong>.</p>
<p>The <strong>sponsor</strong> is responsible for:</p>
<ol>
<li>serving as an escalation point to make quick decisions to avoid getting stuck in development stages</li>
<li>pushing past historical decisions and beliefs that prevent meaningful testing</li>
<li>marshalling cross organizational support</li>
<li>telling the story to stakeholders, especially the executive team to avoid getting defunded</li>
<li>preventing overloading of strategy (where people want to make the strategy solve <em>their</em> semi-related problem)</li>
<li>setting pace to avoid stalling out</li>
<li>identifying when energy is dropping and to change phase of stratey (from development to implementation)</li>
</ol>
<p>The <strong>guide</strong> is responsible for:</p>
<ol>
<li>translating the strategy into particulars where testing gets stuck</li>
<li>identifying slowdowns and blockers</li>
<li>escalating frequently to sponsor</li>
<li>tracking goals and workstreams</li>
<li>maintaining the pace set by the sponsor</li>
</ol>
<p>In terms of filling these roles, there are a few lessons that I&rsquo;ve learned over time.
For sponsors, what matters the most is that they&rsquo;re genuinely authorized by the
company to make the decision they&rsquo;re making, and that they care enough about the impact
that they&rsquo;re willing to make difficult decisions quickly. A sponsor is only meaningful
to the extent that the guide can escalate to the sponsor <em>and</em> they  rapidly resolve those escalations.
If they aren&rsquo;t available for escalations or don&rsquo;t resolve them quickly, they&rsquo;re a poor sponsor.</p>
<p>For guides, you need someone who can execute at pace without getting derailed by various organizational
messes, and has good, nuanced judgment relevant to the strategy being tested.
The worst guides are ideological (they reject the very feedback created by testing)
or easily derailed (you&rsquo;re likely testing <em>because</em> there&rsquo;s friction somewhere, so
someone who can&rsquo;t navigate friction is going to fail by default).</p>
<h2 id="meetings--metrics">Meetings &amp; Metrics</h2>
<p>The only absolute requirement for the strategy testing phase is that
the sponsor, guide, and any key folks working on the strategy <strong>must meet together every single week</strong>.
Within that meeting, you&rsquo;ll iterate on which metrics capture the current areas you&rsquo;re trying to refine,
discuss what you&rsquo;ve learned from prior metrics or data, and schedule one-off followups to ensure you&rsquo;re making progress.</p>
<p>The best version of this meeting is debugging heavy and presentation light.
Any week that you&rsquo;re not learning something that informs subsequent testing,
or making a decision that modifies approach to testing, should be viewed with some suspicion.
It might mean that you&rsquo;ve underresourced the testing effort, or that your testing approach is too
ambitious, but it&rsquo;s a meaningful signal that testing is converging too slowly to maintain attention.</p>
<p>If all of this seems like an overly large commitment, I&rsquo;d push you to consider
your <a href="/when-write-down-engineering-strategy/">strategy altitude</a> to adjust the volume
or permisiveness of the strategy you&rsquo;re working on.
If a strategy isn&rsquo;t worth testing, then it&rsquo;s either already quite good (which should be widely evident beyond its authors)
or it&rsquo;s probably only worth rolling out in a highly permissive format.</p>
<h2 id="identifying-strategies-that-skipped-testing">Identifying strategies that skipped testing</h2>
<p>While not all strategies <em>must</em> be refined by a testing phase, essentially all failing strategies skip
the testing phase to move directly into implementation.
Strategies that skip testing <em>sound right</em>, but don&rsquo;t accomplish much.
Fully standardizing authorization and authentication across your company on one implementation <em>sounds right</em>,
but can still fail if e.g. each team is responsible for its own approach to determining the standard.</p>
<p>One particularly obvious pattern is something I describe as &ldquo;pressure without a plan.&rdquo;
This is a strategy that is <em>only</em> the &ldquo;sounds right&rdquo; aspect with none of the details.
Service migrations are particularly prone to this, perhaps due to apocryphal descriptions of
Amazon&rsquo;s service migration in the 2000s, which is often summarized as a top-down zero-details mandate to switch away from the monolith.</p>
<p>Identification comes down to understanding two things:</p>
<ol>
<li>
<p>Are there numbers that show the strategy is driving the desired impact?
For example, API requests made into the new authentication service as a percentage of all authentication requests
is more meaningful than a spreadsheet tracking teams&rsquo; commitments to move to the new service.</p>
<p>Try to avoid proxy metrics when possible, but to instead look at the actual thing that matters.</p>
</li>
<li>
<p>If the numbers aren&rsquo;t moving, is there a clear mechanism debugging and solving those issues,
and is this team actually making progress?
For example, a team who help integration with the new authentication service to understand
where limitations are preventing effective adoption, and who are shipping working code.</p>
<p>Because the numbers aren&rsquo;t moving, you need to find a different source of meaningful evidence to  validate that progress is happening.
Generally the best bet is either  new software running in a meaningful environment (e.g. production for product code).
It&rsquo;s also useful to talk with skeptics or failed integrations, but be cautious of debugging exclusively with skeptics. <br>
They&rsquo;re almost always right, but often they are out-of-date, such that they&rsquo;re right but aren&rsquo;t describing
current problems.</p>
</li>
</ol>
<p>Unless one of these two identifications are <em>obviously true</em>, then it&rsquo;s very likely that you&rsquo;ve
found a strategy that skipped testing.</p>
<h2 id="recovering-from-skipped-testing">Recovering from skipped testing</h2>
<p>Once you&rsquo;ve recognized a strategy that skipped testing and is now struggling,
the next question is what to do about it.
<a href="/decompose-monolith-strategy/">Should we decompose our monolith?</a> looks at recovering from a failing service migration,
and is lightly based on my experience dealing with similar, stuck service migration at both Calm and Carta.
The answer to a stuck strategy is always: write a new strategy, and make sure <em>not</em> to skip testing this time.</p>
<p>Typically, the first step of this new strategy is explicitly pausing the struggling strategy
while a new testing phase occurs. This is painful to do, because the folks invested in the current
strategy will be upset with you, but there&rsquo;s always going to be people who disagree with any change.
Long-term, the only thing that makes most people happy is a successful strategy, and anything that
delays progress towards is a poor investment.</p>
<p>Sometimes it is difficult to officially pause a struggling strategy,
in which case you have to look for an indirect mechanism to implicitly pause without
acknowledging it. For example, delaying new services while you take a month to invest into improving service provisioning
might give you enough breathing room to test the missing mechanisms from your strategy,
without requiring anyone to lose face that the migration is failing.
It would be nice to always be able to say these things out loud,
but managing personalities is an enduring leadership challenge;
even when your an executive, you just have a different set of messy stakeholders.</p>
<h2 id="summary">Summary</h2>
<p>Testing doesn&rsquo;t determine whether a strategy might be good. It exposes the missing details required to translate
a directionally accurate strategy into a strategy that works.
After reading this chapter, you know how to lead that translation process as both a sponsor
and a guide. You can setup and run the necessary meetings to test a strategy, and also put together
the bank of metrics to determine if the strategy is ready to leave refinement and move to a broader rollout.</p>
<div class="mt4">
        <hr>
        
        <p class="f5"><span class="b mb3">Next chapter: </span> <a href="/strategy-systems-modeling/">Using systems modeling to refine strategy.</a></p>
        
        
        <p class="f5"><span class="b mb3">Previous chapter: </span> <a href="/bridging-eng-strategy-theory-and-practice/">Bridging theory and practice in engineering strategy.</a></p>
                
      </div>
      
      <div class="bg-light-gray br4 ph3 pv1">
        <p class="tracked">First published at <a href="https://lethain.com/testing-strategy-iterative-refinement/">lethain.com/testing-strategy-iterative-refinement/</a></p>      
      </div>
      

      <div class="mt6 instapaper_ignoref">
      
      </div>
    </div>

    <aside class="w-30-l mt1-l"><div class="bg-light-gray pa3 cf">
  <p class="f5 mb3">
    Hi folks. I'm <a href="https://lethain.com/about">Will Larson</a>,
    and this is my new book on engineering strategy, <em><a href="https://draftingstrategy.com/">Drafting Strategy</a></em>.
  </p>

  <p>
    I also wrote

    <em><a href="https://www.amazon.com/Elegant-Puzzle-Systems-Engineering-Management/dp/1732265186">An Elegant Puzzle</a></em>,
    <em><a href="https://staffeng.com/book">Staff Engineer</a></em>, and
      <em><a href="https://www.oreilly.com/library/view/the-engineering-executives/9781098149475/">The Engineering Executive's Primer</a></em>.
  </p>

  <p class="cf">
    <div class="fl w-third">
      <a href="https://www.amazon.com/Elegant-Puzzle-Systems-Engineering-Management/dp/1732265186">
        <img src="/static/aep-small-lq.jpg">
      </a>
    </div>
    <div class="fl w-third">    
      <a href="https://staffeng.com/book">
        <img src="/static/StaffEngBookMed.jpg">
      </a>
    </div>
    <div class="fl w-third">
      <a href="https://www.oreilly.com/library/view/the-engineering-executives/9781098149475/">
        <img src="/static/primer-cover-small.jpg">
      </a>
    </div>    
  </p>
</div>

<div class="bg-light-gray ph3 cf">
  <p class="f5 mb3">
    For updates on this project, join <em>Irrational Exuberance</em>'s
    <a href="/newsletter/">weekly newsletter</a>.
  </p>
</div>


<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
  
    <p class="f5"><span class="b mb3">Next chapter</span></p>
    <p class="f5"><a href="/strategy-systems-modeling/">Using systems modeling to refine strategy.</a></p>
    
    
  
    <p class="f5"><span class="b mb3">Previous chapter</span></p>
    <p class="f5"><a href="/bridging-eng-strategy-theory-and-practice/">Bridging theory and practice in engineering strategy.</a></p>
  
  <p class="f5 b mb3">Table of Contents</p>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#when-to-test-strategy">When to test strategy</a></li>
    <li><a href="#how-to-test-strategy">How to test strategy</a></li>
    <li><a href="#testing-roles-sponsors-and-guides">Testing roles: sponsors and guides</a></li>
    <li><a href="#meetings--metrics">Meetings &amp; Metrics</a></li>
    <li><a href="#identifying-strategies-that-skipped-testing">Identifying strategies that skipped testing</a></li>
    <li><a href="#recovering-from-skipped-testing">Recovering from skipped testing</a></li>
    <li><a href="#summary">Summary</a></li>
  </ul>
</nav>
</div>
</aside>

  </article>

    </main>
    <footer class="bg-white bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="center f4 fw4 hover-white no-underline black-50 dn dib-ns pv2 ph3" href="http://localhost:58150/" >
    &copy;  Will Larson 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
